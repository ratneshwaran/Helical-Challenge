{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9757d7e",
   "metadata": {},
   "source": [
    "# Notebook 1 for in-silico perturbation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d319b808",
   "metadata": {},
   "source": [
    "##### Intialisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e76a7643",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ratne\\Downloads\\Helical_Challenge\\helical_challenge_venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT: C:\\Users\\ratne\\Downloads\\Helical_Challenge\n",
      "RAW_H5AD exists: True\n",
      "PREP_H5AD will be written to: C:\\Users\\ratne\\Downloads\\Helical_Challenge\\data\\prepped\\ALS_snRNA_raw_prepped.h5ad\n",
      "TOKENIZED dir: C:\\Users\\ratne\\Downloads\\Helical_Challenge\\data\\tokenized\n",
      "ISP dir: C:\\Users\\ratne\\Downloads\\Helical_Challenge\\results\\isp\n",
      "MODEL_DIR: C:\\Users\\ratne\\Downloads\\Helical_Challenge\\Geneformer\\Geneformer-V2-104M\n"
     ]
    }
   ],
   "source": [
    "# Task 1 — In-Silico Perturbation Workflow (Geneformer V2)\n",
    "\n",
    "import os, sys, gc, glob, pickle, json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "\n",
    "from geneformer import TranscriptomeTokenizer, InSilicoPerturber\n",
    "\n",
    "# --- project root ---\n",
    "PROJECT = Path(r\"C:\\Users\\ratne\\Downloads\\Helical_Challenge\")\n",
    "\n",
    "# --- data paths ---\n",
    "DATA      = PROJECT / \"data\"\n",
    "RAW_H5AD  = DATA / \"counts_combined_filtered_BA4_sALS_PN.h5ad\"  # raw counts .h5ad\n",
    "\n",
    "# put the prepped file in its own folder so tokenization only sees the right .h5ad\n",
    "PREP_DIR  = DATA / \"prepped\"\n",
    "PREP_H5AD = PREP_DIR / \"ALS_snRNA_raw_prepped.h5ad\"\n",
    "\n",
    "# tokenized dataset + ISP outputs (keep them in your project, not in the Geneformer repo)\n",
    "TOK       = DATA / \"tokenized\"          # Geneformer .dataset will be saved here\n",
    "ISP       = PROJECT / \"results\" / \"isp\" # ISP outputs here\n",
    "DATASET   = TOK / \"ALS.dataset\"\n",
    "\n",
    "# Geneformer V2 model path:\n",
    "# EITHER: local checkpoint folder...\n",
    "MODEL_DIR = str(PROJECT / \"Geneformer\" / \"Geneformer-V2-104M\")\n",
    "# ...OR, alternatively, the HF hub id:\n",
    "# MODEL_DIR = \"ctheodoris/Geneformer/gf-12L-95M-i4096\"\n",
    "\n",
    "# performance knobs\n",
    "NPROC     = 4\n",
    "FWD_BATCH = 16\n",
    "MODEL_VER = \"V2\"\n",
    "\n",
    "# make output dirs\n",
    "for p in [PREP_DIR, TOK, ISP]:\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"PROJECT:\", PROJECT)\n",
    "print(\"RAW_H5AD exists:\", RAW_H5AD.exists())\n",
    "print(\"PREP_H5AD will be written to:\", PREP_H5AD)\n",
    "print(\"TOKENIZED dir:\", TOK)\n",
    "print(\"ISP dir:\", ISP)\n",
    "print(\"MODEL_DIR:\", MODEL_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dbe53fa",
   "metadata": {},
   "source": [
    "##### Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74a1a3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- 1) Load raw data ----------\n",
    "assert RAW_H5AD.exists(), f\"Raw .h5ad not found at {RAW_H5AD}\"\n",
    "adata = sc.read_h5ad(RAW_H5AD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0e7fb56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subsampled: 1000 cells\n"
     ]
    }
   ],
   "source": [
    "# starting from your full adata *before* writing PREP_H5AD\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(0)\n",
    "n_cells = 1000   # or 2000, something smallish\n",
    "idx = np.random.choice(adata.obs_names, size=n_cells, replace=False)\n",
    "adata_small = adata[idx].copy()\n",
    "\n",
    "print(\"Subsampled:\", adata_small.n_obs, \"cells\")\n",
    "\n",
    "# then continue preprocessing *on adata_small* instead of adata:\n",
    "adata = adata_small\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6838c3fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading gene name→Ensembl mapping: C:\\Users\\ratne\\Downloads\\Helical_Challenge\\Geneformer\\geneformer\\gene_name_id_dict_gc104M.pkl\n",
      "No 'ensembl_id' column; starting from var index as symbols.\n",
      "-> Kept 0 existing Ensembl IDs.\n",
      "-> Converted 22831 symbols to Ensembl IDs via mapping.\n",
      "-> 1 genes still lack Ensembl IDs.\n",
      "Example ensembl_id values: ['ENSG00000000003', 'ENSG00000000005', 'ENSG00000000419', 'ENSG00000000457', 'ENSG00000000938']\n",
      "Genes: 22832, cells: 1000\n",
      "Has 'ensembl_id' in var: True\n",
      "Added 'n_counts' from total_counts\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import pickle\n",
    "\n",
    "# ---------- 1) sanity check on counts ----------\n",
    "mtx_max = adata.X.max() if not hasattr(adata.X, \"A\") else adata.X.A.max()\n",
    "if float(mtx_max) < 50:\n",
    "    print(\"NOTE: Matrix max is <50. Ensure this is RAW counts, not log/CPM.\")\n",
    "\n",
    "# ---------- 2) Ensure Ensembl IDs in adata.var[\"ensembl_id\"] ----------\n",
    "\n",
    "gene_name_id_path = PROJECT / \"Geneformer\" / \"geneformer\" / \"gene_name_id_dict_gc104M.pkl\"\n",
    "if not gene_name_id_path.exists():\n",
    "    raise FileNotFoundError(f\"Mapping dict not found at {gene_name_id_path}\")\n",
    "\n",
    "print(\"Loading gene name→Ensembl mapping:\", gene_name_id_path)\n",
    "with open(gene_name_id_path, \"rb\") as f:\n",
    "    gene_name_id_dict = pickle.load(f)\n",
    "\n",
    "# Start from existing 'ensembl_id' if present, otherwise from gene symbols in var.index\n",
    "if \"ensembl_id\" in adata.var.columns:\n",
    "    ens = adata.var[\"ensembl_id\"].astype(object).to_numpy()\n",
    "    print(\"Found existing 'ensembl_id' column; will keep valid ENSG IDs and fill the rest.\")\n",
    "else:\n",
    "    ens = adata.var.index.astype(str).to_numpy().astype(object)\n",
    "    print(\"No 'ensembl_id' column; starting from var index as symbols.\")\n",
    "\n",
    "symbols = adata.var.index.astype(str).to_numpy()\n",
    "\n",
    "converted = 0\n",
    "skipped_existing = 0\n",
    "pattern = re.compile(r\"^ENSG\\d+\")\n",
    "\n",
    "for i in range(len(ens)):\n",
    "    val = ens[i]\n",
    "    s = \"\" if val is None else str(val)\n",
    "\n",
    "    # If already a valid Ensembl ID, keep it\n",
    "    if pattern.match(s):\n",
    "        skipped_existing += 1\n",
    "        continue\n",
    "\n",
    "    # Otherwise, map from gene symbol (var index)\n",
    "    sym = symbols[i]\n",
    "    mapped = gene_name_id_dict.get(sym)\n",
    "    if mapped is not None:\n",
    "        ens[i] = mapped\n",
    "        converted += 1\n",
    "    else:\n",
    "        ens[i] = None  # mark unmapped\n",
    "\n",
    "adata.var[\"ensembl_id\"] = ens\n",
    "\n",
    "n_missing = pd.isna(adata.var[\"ensembl_id\"]).sum()\n",
    "print(f\"-> Kept {skipped_existing} existing Ensembl IDs.\")\n",
    "print(f\"-> Converted {converted} symbols to Ensembl IDs via mapping.\")\n",
    "print(f\"-> {n_missing} genes still lack Ensembl IDs.\")\n",
    "print(\"Example ensembl_id values:\", adata.var['ensembl_id'].head().tolist())\n",
    "\n",
    "# ---------- 3) Required obs fields ----------\n",
    "# Geneformer needs per-cell total counts in 'n_counts'\n",
    "if \"total_counts\" in adata.obs.columns:\n",
    "    adata.obs[\"n_counts\"] = adata.obs[\"total_counts\"].astype(np.float64)\n",
    "else:\n",
    "    if hasattr(adata.X, \"A\"):\n",
    "        adata.obs[\"n_counts\"] = np.array(adata.X.sum(axis=1)).ravel()\n",
    "    else:\n",
    "        adata.obs[\"n_counts\"] = adata.X.sum(axis=1)\n",
    "\n",
    "adata.obs[\"filter_pass\"] = True\n",
    "\n",
    "print(f\"Genes: {adata.n_vars}, cells: {adata.n_obs}\")\n",
    "print(\"Has 'ensembl_id' in var:\", \"ensembl_id\" in adata.var.columns)\n",
    "print(\"Added 'n_counts' from total_counts\" if \"total_counts\" in adata.obs.columns else \"Computed 'n_counts' by summing X\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af10ad45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping 1 genes with no Ensembl ID.\n"
     ]
    }
   ],
   "source": [
    "mask = adata.var[\"ensembl_id\"].notna()\n",
    "print(\"Dropping\", (~mask).sum(), \"genes with no Ensembl ID.\")\n",
    "adata = adata[:, mask].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd7c56ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will keep obs columns: ['Sample_ID', 'Donor', 'Region', 'Sex', 'Condition', 'Group', 'C9_pos', 'CellClass', 'CellType', 'SubType', 'Cellstates_LVL1', 'Cellstates_LVL2', 'Cellstates_LVL3', 'total_counts', 'log1p_total_counts', 'total_counts_mt', 'log1p_total_counts_mt', 'pct_counts_mt', 'n_genes', 'split', 'n_counts']\n",
      "Wrote prepped AnnData to: C:\\Users\\ratne\\Downloads\\Helical_Challenge\\data\\prepped\\ALS_snRNA_raw_prepped.h5ad\n"
     ]
    }
   ],
   "source": [
    "# obs metadata to carry into the .dataset file\n",
    "\n",
    "obs_to_keep = [\n",
    "    \"Sample_ID\", \"Donor\", \"Region\", \"Sex\",\n",
    "    \"Condition\", \"Group\", \"C9_pos\",\n",
    "    \"CellClass\", \"CellType\", \"SubType\",\n",
    "    \"Cellstates_LVL1\", \"Cellstates_LVL2\", \"Cellstates_LVL3\",\n",
    "    \"total_counts\", \"log1p_total_counts\",\n",
    "    \"total_counts_mt\", \"log1p_total_counts_mt\", \"pct_counts_mt\",\n",
    "    \"n_genes\",\n",
    "    \"split\",\n",
    "    # you already added:\n",
    "    \"n_counts\"\n",
    "]\n",
    "\n",
    "present = [k for k in obs_to_keep if k in adata.obs.columns]\n",
    "missing = [k for k in obs_to_keep if k not in adata.obs.columns]\n",
    "print(\"Will keep obs columns:\", present)\n",
    "if missing:\n",
    "    print(\"Missing (ignored):\", missing)\n",
    "\n",
    "custom_attr_name_dict = {k: k for k in present}\n",
    "\n",
    "# cast non-numeric obs to string so they survive round-trips nicely\n",
    "for k in present:\n",
    "    if adata.obs[k].dtype.kind not in {\"i\", \"f\"}:\n",
    "        adata.obs[k] = adata.obs[k].astype(str)\n",
    "\n",
    "# Save prepped AnnData\n",
    "PREP_H5AD.parent.mkdir(parents=True, exist_ok=True)\n",
    "adata.write_h5ad(PREP_H5AD)\n",
    "print(\"Wrote prepped AnnData to:\", PREP_H5AD)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f2ed62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensembl IDs in var: Gene\n",
      "TSPAN6    ENSG00000000003\n",
      "TNMD      ENSG00000000005\n",
      "DPM1      ENSG00000000419\n",
      "SCYL3     ENSG00000000457\n",
      "FGR       ENSG00000000938\n",
      "               ...       \n",
      "CROT      ENSG00000005469\n",
      "ABCB4     ENSG00000005471\n",
      "KMT2E     ENSG00000005483\n",
      "RHBDD2    ENSG00000005486\n",
      "SOX8      ENSG00000005513\n",
      "Name: ensembl_id, Length: 100, dtype: object\n",
      "\n",
      "\n",
      "Obs fields:                                        Sample_ID Donor Region Sex Condition  \\\n",
      "Barcode                                                                       \n",
      "GTCGTTCTCTGTGCAA-118MCX  191112_ALS_118_snRNA-C4   118    BA4   M       ALS   \n",
      "GGGCTCATCTGGGAGA-126MCX  191112_ALS_126_snRNA-A6   126    BA4   M       ALS   \n",
      "GTAACACTCGTCCATC-303MCX   191114_PN_303_snRNA-E8   303    BA4   F        PN   \n",
      "AGCCAGCGTCGTTCAA-116MCX  191112_ALS_116_snRNA-C2   116    BA4   M       ALS   \n",
      "ATTCGTTTCAAGCTGT-309MCX   191114_PN_309_snRNA-F1   309    BA4   F        PN   \n",
      "...                                          ...   ...    ...  ..       ...   \n",
      "ATGGTTGGTGGATCAG-306MCX  191114_PN_306_snRNA-E10   306    BA4   F        PN   \n",
      "AGGATCTCATCCTATT-324MCX   191114_PN_324_snRNA-F7   324    BA4   M        PN   \n",
      "AGGACGAAGTCGCGAA-116MCX  191112_ALS_116_snRNA-C2   116    BA4   M       ALS   \n",
      "CAGATTGCATTGAGCT-302MCX   200721_PN_302_snRNA-B4   302    BA4   F        PN   \n",
      "AACACACTCTTGGCTC-317MCX   191114_PN_317_snRNA-F2   317    BA4   M        PN   \n",
      "\n",
      "                        Group C9_pos CellClass CellType         SubType  ...  \\\n",
      "Barcode                                                                  ...   \n",
      "GTCGTTCTCTGTGCAA-118MCX  SALS    0.0        Ex       L6     TLE4_SEMA3D  ...   \n",
      "GGGCTCATCTGGGAGA-126MCX  SALS    0.0        In       PV     PVALB_CEMIP  ...   \n",
      "GTAACACTCGTCCATC-303MCX    PN    0.0        Ex    L5_L6  THEMIS_TMEM233  ...   \n",
      "AGCCAGCGTCGTTCAA-116MCX  SALS    0.0        Ex       L6     TLE4_MEGF11  ...   \n",
      "ATTCGTTTCAAGCTGT-309MCX    PN    0.0        Ex    L2_L3    CUX2_RASGRF2  ...   \n",
      "...                       ...    ...       ...      ...             ...  ...   \n",
      "ATGGTTGGTGGATCAG-306MCX    PN    0.0      Glia    Oligo             nan  ...   \n",
      "AGGATCTCATCCTATT-324MCX    PN    0.0      Glia    Micro             nan  ...   \n",
      "AGGACGAAGTCGCGAA-116MCX  SALS    0.0      Glia    Astro        GFAP-neg  ...   \n",
      "CAGATTGCATTGAGCT-302MCX    PN    0.0        Ex    L2_L3    CUX2_RASGRF2  ...   \n",
      "AACACACTCTTGGCTC-317MCX    PN    0.0      Glia      OPC             nan  ...   \n",
      "\n",
      "                        Cellstates_LVL1 Cellstates_LVL2  \\\n",
      "Barcode                                                   \n",
      "GTCGTTCTCTGTGCAA-118MCX              Ex           Ex_L6   \n",
      "GGGCTCATCTGGGAGA-126MCX              In           In_PV   \n",
      "GTAACACTCGTCCATC-303MCX              Ex        Ex_L5_L6   \n",
      "AGCCAGCGTCGTTCAA-116MCX              Ex           Ex_L6   \n",
      "ATTCGTTTCAAGCTGT-309MCX              Ex        Ex_L2_L3   \n",
      "...                                 ...             ...   \n",
      "ATGGTTGGTGGATCAG-306MCX            Glia           Oligo   \n",
      "AGGATCTCATCCTATT-324MCX            Glia           Micro   \n",
      "AGGACGAAGTCGCGAA-116MCX            Glia           Astro   \n",
      "CAGATTGCATTGAGCT-302MCX              Ex        Ex_L2_L3   \n",
      "AACACACTCTTGGCTC-317MCX            Glia             OPC   \n",
      "\n",
      "                                 Cellstates_LVL3 total_counts_mt  \\\n",
      "Barcode                                                            \n",
      "GTCGTTCTCTGTGCAA-118MCX        Ex.L6.TLE4_SEMA3D             231   \n",
      "GGGCTCATCTGGGAGA-126MCX        In.PV.PVALB_CEMIP             115   \n",
      "GTAACACTCGTCCATC-303MCX  Ex.L5_L6.THEMIS_TMEM233             908   \n",
      "AGCCAGCGTCGTTCAA-116MCX        Ex.L6.TLE4_MEGF11              43   \n",
      "ATTCGTTTCAAGCTGT-309MCX    Ex.L2_L3.CUX2_RASGRF2             562   \n",
      "...                                          ...             ...   \n",
      "ATGGTTGGTGGATCAG-306MCX               Glia.Oligo              58   \n",
      "AGGATCTCATCCTATT-324MCX               Glia.Micro               2   \n",
      "AGGACGAAGTCGCGAA-116MCX      Glia.Astro.GFAP-neg              44   \n",
      "CAGATTGCATTGAGCT-302MCX    Ex.L2_L3.CUX2_RASGRF2             327   \n",
      "AACACACTCTTGGCTC-317MCX                 Glia.OPC               0   \n",
      "\n",
      "                        log1p_total_counts_mt  pct_counts_mt  n_genes  split  \\\n",
      "Barcode                                                                        \n",
      "GTCGTTCTCTGTGCAA-118MCX              5.446737       1.548050     4823  train   \n",
      "GGGCTCATCTGGGAGA-126MCX              4.753590       1.170483     3780  train   \n",
      "GTAACACTCGTCCATC-303MCX              6.812345       2.159745     7880  train   \n",
      "AGCCAGCGTCGTTCAA-116MCX              3.784190       0.554696     3138  train   \n",
      "ATTCGTTTCAAGCTGT-309MCX              6.333280       2.568438     6476  train   \n",
      "...                                       ...            ...      ...    ...   \n",
      "ATGGTTGGTGGATCAG-306MCX              4.077537       1.397927     2069  train   \n",
      "AGGATCTCATCCTATT-324MCX              1.098612       0.148368      967   test   \n",
      "AGGACGAAGTCGCGAA-116MCX              3.806662       0.621293     3128  train   \n",
      "CAGATTGCATTGAGCT-302MCX              5.793014       3.320808     4046  train   \n",
      "AACACACTCTTGGCTC-317MCX              0.000000       0.000000     3101  train   \n",
      "\n",
      "                         n_counts filter_pass  \n",
      "Barcode                                        \n",
      "GTCGTTCTCTGTGCAA-118MCX   14922.0        True  \n",
      "GGGCTCATCTGGGAGA-126MCX    9825.0        True  \n",
      "GTAACACTCGTCCATC-303MCX   42042.0        True  \n",
      "AGCCAGCGTCGTTCAA-116MCX    7752.0        True  \n",
      "ATTCGTTTCAAGCTGT-309MCX   21881.0        True  \n",
      "...                           ...         ...  \n",
      "ATGGTTGGTGGATCAG-306MCX    4149.0        True  \n",
      "AGGATCTCATCCTATT-324MCX    1348.0        True  \n",
      "AGGACGAAGTCGCGAA-116MCX    7082.0        True  \n",
      "CAGATTGCATTGAGCT-302MCX    9847.0        True  \n",
      "AACACACTCTTGGCTC-317MCX    7698.0        True  \n",
      "\n",
      "[100 rows x 29 columns]\n"
     ]
    }
   ],
   "source": [
    "after_adata = sc.read_h5ad(PREP_H5AD)\n",
    "\n",
    "# checking the ensembl_ids\n",
    "print(\"Ensembl IDs in var:\", after_adata.var[\"ensembl_id\"].head(100))\n",
    "print(\"\\n\")\n",
    "# checking the obs\n",
    "print(\"Obs fields:\", after_adata.obs.head(100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36597b30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "Device: NVIDIA GeForce RTX 3050 Ti Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Device:\", torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74fcb46",
   "metadata": {},
   "source": [
    "##### Tokenise the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1051ea9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing with Geneformer V2…\n",
      "Using data directory: C:\\Users\\ratne\\Downloads\\Helical_Challenge\\data\\prepped\n",
      "Tokenizing C:\\Users\\ratne\\Downloads\\Helical_Challenge\\data\\prepped\\ALS_snRNA_raw_prepped.h5ad\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ratne\\Downloads\\Helical_Challenge\\helical_challenge_venv\\lib\\site-packages\\geneformer\\tokenizer.py:544: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  for i in adata.var[\"ensembl_id_collapsed\"][coding_miRNA_loc]\n",
      "c:\\Users\\ratne\\Downloads\\Helical_Challenge\\helical_challenge_venv\\lib\\site-packages\\geneformer\\tokenizer.py:547: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  coding_miRNA_ids = adata.var[\"ensembl_id_collapsed\"][coding_miRNA_loc]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dataset.\n",
      "Done. Dataset exists: True at C:\\Users\\ratne\\Downloads\\Helical_Challenge\\data\\tokenized\\ALS.dataset\n"
     ]
    }
   ],
   "source": [
    "# Cell 4 — Tokenize with Geneformer V2\n",
    "\n",
    "TOKENIZED_DIR = DATA / \"tokenized\"\n",
    "TOKENIZED_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Tokenizing with Geneformer V2…\")\n",
    "print(\"Using data directory:\", PREP_DIR)\n",
    "\n",
    "tk = TranscriptomeTokenizer(\n",
    "    custom_attr_name_dict=custom_attr_name_dict,\n",
    "    nproc=NPROC,\n",
    "    model_version=MODEL_VER\n",
    ")\n",
    "\n",
    "tk.tokenize_data(\n",
    "    data_directory=str(PREP_DIR),   # folder containing only the prepped .h5ad\n",
    "    output_directory=str(TOKENIZED_DIR),\n",
    "    output_prefix=\"ALS\",\n",
    "    file_format=\"h5ad\"\n",
    ")\n",
    "\n",
    "DATASET = TOKENIZED_DIR / \"ALS.dataset\"\n",
    "print(\"Done. Dataset exists:\", DATASET.exists(), \"at\", DATASET)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9951bc4c",
   "metadata": {},
   "source": [
    "##### Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "337b84fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5 — In-silico perturbation helpers (knock-down / knock-up)\n",
    "\n",
    "import gc\n",
    "\n",
    "# ISP output directory\n",
    "ISP = PROJECT / \"results\" / \"isp\"\n",
    "ISP.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# genes present in the (prepped) matrix\n",
    "genes_in_matrix = set(adata.var[\"ensembl_id\"].astype(str).tolist())\n",
    "\n",
    "def verify_genes_present(ensg_list):\n",
    "    \"\"\"Split requested Ensembl IDs into present vs missing.\"\"\"\n",
    "    ensg_list = [str(x) for x in ensg_list]\n",
    "    present = [g for g in ensg_list if g in genes_in_matrix]\n",
    "    missing = [g for g in ensg_list if g not in genes_in_matrix]\n",
    "    return present, missing\n",
    "\n",
    "def run_isp(\n",
    "    genes_to_perturb,\n",
    "    perturb_type,                 # \"delete\" (KD) or \"overexpress\" (KU)\n",
    "    out_prefix,\n",
    "    model_directory=MODEL_DIR,\n",
    "    dataset_file=DATASET,\n",
    "    emb_mode=\"cls\",\n",
    "    emb_layer=-1,\n",
    "    forward_batch_size=FWD_BATCH,\n",
    "    nproc=NPROC,\n",
    "    model_version=MODEL_VER,\n",
    "    combos=0,\n",
    "    anchor_gene=None\n",
    "):\n",
    "    \"\"\"Run Geneformer InSilicoPerturber for a list of Ensembl IDs.\"\"\"\n",
    "    present, missing = verify_genes_present(genes_to_perturb)\n",
    "    if missing:\n",
    "        print(f\"[WARN] {len(missing)} gene(s) not in matrix (skipped):\", missing[:10], \"...\")\n",
    "    if not present:\n",
    "        print(\"[SKIP] no valid genes to perturb in this call.\")\n",
    "        return\n",
    "\n",
    "    isp = InSilicoPerturber(\n",
    "        perturb_type=perturb_type,           # \"delete\" / \"overexpress\"\n",
    "        genes_to_perturb=present,            # list of Ensembl IDs\n",
    "        combos=combos,\n",
    "        anchor_gene=anchor_gene,\n",
    "        model_type=\"Pretrained\",\n",
    "        emb_mode=emb_mode,\n",
    "        emb_layer=emb_layer,\n",
    "        forward_batch_size=forward_batch_size,\n",
    "        nproc=nproc,\n",
    "        model_version=model_version\n",
    "    )\n",
    "    isp.perturb_data(\n",
    "        model_directory=str(model_directory),\n",
    "        input_data_file=str(dataset_file),\n",
    "        output_directory=str(ISP),\n",
    "        output_prefix=out_prefix\n",
    "    )\n",
    "    print(f\"[ISP] {perturb_type}: {len(present)} gene(s) -> {ISP} (prefix={out_prefix})\")\n",
    "\n",
    "def chunked(lst, size):\n",
    "    for i in range(0, len(lst), size):\n",
    "        yield lst[i:i+size]\n",
    "\n",
    "def run_isp_batched(genes, perturb_type, prefix, batch_size=25):\n",
    "    \"\"\"Scale to many genes by chunking.\"\"\"\n",
    "    for i, gbatch in enumerate(chunked(genes, batch_size), 1):\n",
    "        run_isp(gbatch, perturb_type, f\"{prefix}_b{i:03d}\")\n",
    "        gc.collect()\n",
    "    print(f\"[ISP] completed all batches for {prefix}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "85060e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6 — Helper to load ISP outputs and summarize per gene\n",
    "\n",
    "def load_isp_batches(prefix):\n",
    "    \"\"\"Read all batch .pkl files starting with prefix into a DataFrame.\"\"\"\n",
    "    rows = []\n",
    "    for f in sorted(ISP.glob(f\"{prefix}*batch*.pkl\")):\n",
    "        with open(f, \"rb\") as fh:\n",
    "            b = pickle.load(fh)\n",
    "        n = len(b.get(\"cell_ids\", []))\n",
    "        gene_ids = b.get(\"gene_id\", b.get(\"gene_ids\", [\"?\"] * n))\n",
    "        cos = b.get(\"cosine_shift\", [np.nan] * n)\n",
    "        for i in range(n):\n",
    "            rows.append({\n",
    "                \"batch_file\": f.name,\n",
    "                \"cell_id\": b[\"cell_ids\"][i],\n",
    "                \"gene_id\": gene_ids[i],\n",
    "                \"cosine_shift\": float(cos[i]) if not isinstance(cos, float) else float(cos),\n",
    "            })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "def summarize_isp(prefix, topn=15):\n",
    "    df = load_isp_batches(prefix)\n",
    "    if df.empty:\n",
    "        print(\"No ISP batches found for\", prefix)\n",
    "        return df, None\n",
    "    summary = (df.groupby(\"gene_id\")[\"cosine_shift\"]\n",
    "                 .median()\n",
    "                 .sort_values(ascending=False)\n",
    "                 .rename(\"median_cosine_shift\")\n",
    "                 .reset_index())\n",
    "    display(summary.head(topn))\n",
    "    return df, summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9546df8",
   "metadata": {},
   "source": [
    "##### Quick sample test: single-gene KD + KU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a84cbf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gene\n",
      "TSPAN6    ENSG00000000003\n",
      "TNMD      ENSG00000000005\n",
      "DPM1      ENSG00000000419\n",
      "SCYL3     ENSG00000000457\n",
      "FGR       ENSG00000000938\n",
      "Name: ensembl_id, dtype: object\n",
      "Using test gene: ENSG00000000003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [01:56<00:00, 116.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ISP] delete: 1 gene(s) -> C:\\Users\\ratne\\Downloads\\Helical_Challenge\\results\\isp (prefix=SMOKE_KD)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [1:38:01<00:00, 93.36s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ISP] overexpress: 1 gene(s) -> C:\\Users\\ratne\\Downloads\\Helical_Challenge\\results\\isp (prefix=SMOKE_KU)\n",
      "No ISP batches found for SMOKE_KD\n",
      "No ISP batches found for SMOKE_KU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell 7 — Smoke test: perturb a single gene\n",
    "\n",
    "# Pick an Ensembl ID you know is present in your data:\n",
    "print(adata.var[\"ensembl_id\"].head())\n",
    "\n",
    "TEST_GENE = adata.var[\"ensembl_id\"].iloc[0]   # quick hack: just take the first one\n",
    "print(\"Using test gene:\", TEST_GENE)\n",
    "\n",
    "# Knock-down (delete)\n",
    "run_isp([TEST_GENE], \"delete\", \"SMOKE_KD\")\n",
    "\n",
    "# Knock-up (overexpress)\n",
    "run_isp([TEST_GENE], \"overexpress\", \"SMOKE_KU\")\n",
    "\n",
    "# Summaries (if any batches were written)\n",
    "_, kd_summary = summarize_isp(\"SMOKE_KD\")\n",
    "_, ku_summary = summarize_isp(\"SMOKE_KU\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab52067b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ISP directory: C:\\Users\\ratne\\Downloads\\Helical_Challenge\\results\\isp\n",
      " - in_silico_delete_SMOKE_KD_cell_embs_dict_[4]_raw.pickle\n",
      " - in_silico_overexpress_SMOKE_KU_cell_embs_dict_[4]_raw.pickle\n",
      "\n",
      "in_silico_delete_SMOKE_KD_cell_embs_dict_[4]_raw.pickle:\n",
      "  raw keys: [(4, 'cell_emb')]\n",
      "  number of cells: 12\n",
      "  type of first element: <class 'float'>\n",
      "  embedding array shape: (12,)\n",
      "\n",
      "in_silico_overexpress_SMOKE_KU_cell_embs_dict_[4]_raw.pickle:\n",
      "  raw keys: [(4, 'cell_emb')]\n",
      "  number of cells: 1000\n",
      "  type of first element: <class 'float'>\n",
      "  embedding array shape: (1000,)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"ISP directory:\", ISP)\n",
    "for f in sorted(ISP.glob(\"*.pickle\")):\n",
    "    print(\" -\", f.name)\n",
    "\n",
    "def load_cell_embs(path):\n",
    "    \"\"\"Load Geneformer ISP cell embeddings from a cell_embs_dict file.\"\"\"\n",
    "    with open(path, \"rb\") as fh:\n",
    "        d = pickle.load(fh)\n",
    "\n",
    "    print(f\"\\n{Path(path).name}:\")\n",
    "    print(\"  raw keys:\", list(d.keys()))\n",
    "\n",
    "    # Find the (layer_idx, 'cell_emb') key\n",
    "    key = None\n",
    "    for k in d.keys():\n",
    "        if isinstance(k, tuple) and \"cell_emb\" in k[1]:\n",
    "            key = k\n",
    "            break\n",
    "\n",
    "    if key is None:\n",
    "        raise ValueError(\"Could not find a 'cell_emb' key in this dict.\")\n",
    "\n",
    "    raw = d[key]           # list/array of length N_cells, each element is a vector\n",
    "    print(\"  number of cells:\", len(raw))\n",
    "    print(\"  type of first element:\", type(raw[0]))\n",
    "\n",
    "    # Stack into a 2D array: (n_cells, emb_dim)\n",
    "    embs = np.stack(raw, axis=0)\n",
    "    print(\"  embedding array shape:\", embs.shape)\n",
    "\n",
    "    return embs\n",
    "\n",
    "# Load both KD and KU results\n",
    "kd_path = next(ISP.glob(\"*SMOKE_KD*.pickle\"))\n",
    "ku_path = next(ISP.glob(\"*SMOKE_KU*.pickle\"))\n",
    "\n",
    "kd_embs = load_cell_embs(kd_path)\n",
    "ku_embs = load_cell_embs(ku_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "helical_challenge_venv (3.10.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
